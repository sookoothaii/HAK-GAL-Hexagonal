#!/usr/bin/env python3
"""
HAK-GAL Autonomous Predicate Explorer & Learning Loop
======================================================
Automatischer Kreislauf der neue Pr√§dikate erkennt, exploriert und lernt
Implementiert echtes selbstlernendes Verhalten

Nach HAK/GAL Verfassung:
- Artikel 1: Komplement√§re Intelligenz (LLM + HRM zusammen)
- Artikel 4: Bewusstes Grenz√ºberschreiten (neue Gebiete explorieren)
- Artikel 7: Konjugierte Zust√§nde (Neural + Symbolic lernen)
"""

import requests
import json
import sqlite3
import time
import random
from datetime import datetime
from typing import Dict, List, Tuple, Set
from collections import defaultdict

BACKEND_URL = 'http://localhost:5002'
DATABASE_PATH = r'D:\MCP Mods\HAK_GAL_HEXAGONAL\hexagonal_kb.db'
EXPLORATION_LOG = 'predicate_exploration_log.json'

class AutonomousPredicateExplorer:
    """
    Selbstlernender Kreislauf f√ºr neue Pr√§dikate
    
    WORKFLOW:
    1. DISCOVER: Findet neue Pr√§dikate in der KB
    2. EXPLORE: Generiert Facts mit neuen Pr√§dikaten via LLM
    3. TEST: Testet HRM Confidence f√ºr neue Facts
    4. LEARN: F√ºgt erfolgreiche Facts hinzu
    5. ADAPT: Mappt schlechte Pr√§dikate zu guten
    6. EVOLVE: Wiederholt mit verbessertem Wissen
    """
    
    def __init__(self):
        # Bekannte gute Pr√§dikate (>70% HRM confidence)
        self.known_good_predicates = {
            'HasProperty': 0.85,
            'HasPart': 0.80,
            'Causes': 0.75,
            'IsA': 0.90,
            'Uses': 0.70,
        }
        
        # Unbekannte/neue Pr√§dikate zum Explorieren
        self.unknown_predicates = set()
        
        # Predicate Performance Tracking
        self.predicate_scores = defaultdict(list)
        
        # Learning History
        self.exploration_history = []
        
        # Adaptive Mappings (learned over time)
        self.learned_mappings = {}
        
        # Statistics
        self.stats = {
            'predicates_discovered': 0,
            'facts_generated': 0,
            'facts_accepted': 0,
            'confidence_improvements': 0,
            'new_domains_explored': set()
        }
    
    def discover_new_predicates(self) -> Set[str]:
        """
        Phase 1: DISCOVER
        Findet neue Pr√§dikate in der Datenbank
        """
        print("\nüîç PHASE 1: DISCOVERING NEW PREDICATES...")
        print("="*60)
        
        try:
            conn = sqlite3.connect(DATABASE_PATH)
            cursor = conn.cursor()
            
            # Alle Pr√§dikate finden
            cursor.execute("""
                SELECT DISTINCT
                    SUBSTR(statement, 1, INSTR(statement, '(') - 1) as predicate,
                    COUNT(*) as count
                FROM facts
                WHERE statement LIKE '%(%'
                AND predicate != ''
                GROUP BY predicate
            """)
            
            all_predicates = cursor.fetchall()
            conn.close()
            
            new_predicates = set()
            for pred, count in all_predicates:
                if pred and pred not in self.known_good_predicates:
                    new_predicates.add(pred)
                    if count < 10:  # Seltene Pr√§dikate sind interessant
                        print(f"  üÜï Rare predicate found: {pred} ({count} facts)")
                    else:
                        print(f"  üìù Unknown predicate: {pred} ({count} facts)")
            
            self.unknown_predicates = new_predicates
            self.stats['predicates_discovered'] = len(new_predicates)
            
            print(f"\n  Found {len(new_predicates)} unknown predicates to explore")
            
            return new_predicates
            
        except Exception as e:
            print(f"  ‚ùå Error discovering predicates: {e}")
            return set()
    
    def explore_predicate_with_llm(self, predicate: str) -> List[str]:
        """
        Phase 2: EXPLORE
        Nutzt LLM um neue Facts mit dem Pr√§dikat zu generieren
        """
        print(f"\n  ü§ñ Exploring '{predicate}' with LLM...")
        
        # Erstelle exploratory prompt
        exploration_prompt = f"""
        Generate 5 diverse facts using the predicate '{predicate}'.
        Examples of what {predicate} might mean:
        - If it's about relationships: {predicate}(EntityA, EntityB)
        - If it's about properties: {predicate}(Entity, Property)
        - If it's about actions: {predicate}(Actor, Target)
        
        Generate creative but plausible facts that explore different domains:
        philosophy, science, technology, geography, history.
        """
        
        try:
            # LLM API call
            response = requests.post(
                f"{BACKEND_URL}/api/llm/get-explanation",
                json={
                    'topic': exploration_prompt,
                    'context_facts': []
                },
                headers={'Content-Type': 'application/json'},
                timeout=30
            )
            
            if response.ok:
                data = response.json()
                suggested_facts = []
                
                # Extract facts from LLM response
                for fact_obj in data.get('suggested_facts', []):
                    if isinstance(fact_obj, dict):
                        fact = fact_obj.get('fact', '')
                    else:
                        fact = str(fact_obj)
                    
                    # Ensure it uses our predicate
                    if fact and predicate in fact:
                        suggested_facts.append(fact)
                
                # If no facts with our predicate, create some
                if not suggested_facts:
                    domains = ['Philosophy', 'Technology', 'Science', 'Geography', 'History']
                    entities = ['Quantum', 'Democracy', 'Evolution', 'Internet', 'Renaissance']
                    
                    for i in range(3):
                        entity1 = random.choice(entities)
                        entity2 = random.choice(domains)
                        fact = f"{predicate}({entity1}, {entity2})."
                        suggested_facts.append(fact)
                
                print(f"    Generated {len(suggested_facts)} exploratory facts")
                return suggested_facts
                
            else:
                print(f"    ‚ö†Ô∏è LLM response failed: {response.status_code}")
                return []
                
        except Exception as e:
            print(f"    ‚ùå LLM exploration error: {e}")
            return []
    
    def test_fact_confidence(self, fact: str) -> float:
        """
        Phase 3: TEST
        Testet HRM Confidence f√ºr einen Fact
        """
        try:
            response = requests.post(
                f"{BACKEND_URL}/api/reason",
                json={'query': fact},
                headers={'Content-Type': 'application/json'},
                timeout=10
            )
            
            if response.ok:
                confidence = response.json().get('confidence', 0.0)
                return confidence
            return 0.0
            
        except:
            return 0.0
    
    def learn_from_exploration(self, predicate: str, test_results: List[Tuple[str, float]]):
        """
        Phase 4: LEARN
        Lernt aus den Test-Ergebnissen
        """
        print(f"\n  üìö Learning from {predicate} exploration...")
        
        # Analysiere Ergebnisse
        confidences = [conf for _, conf in test_results]
        avg_confidence = sum(confidences) / len(confidences) if confidences else 0
        
        # Update predicate score
        self.predicate_scores[predicate].append(avg_confidence)
        
        # Entscheide basierend auf Confidence
        if avg_confidence > 0.7:
            print(f"    ‚úÖ {predicate} is GOOD (avg: {avg_confidence:.1%})")
            self.known_good_predicates[predicate] = avg_confidence
            
            # F√ºge erfolgreiche Facts zur DB hinzu
            for fact, conf in test_results:
                if conf > 0.6:
                    self._add_fact_to_db(fact, 'autonomous_exploration', conf)
                    
        elif avg_confidence > 0.3:
            print(f"    ‚ö†Ô∏è {predicate} is MEDIOCRE (avg: {avg_confidence:.1%})")
            # Versuche Mapping zu finden
            self._find_better_mapping(predicate, test_results)
            
        else:
            print(f"    ‚ùå {predicate} is UNKNOWN to HRM (avg: {avg_confidence:.1%})")
            # Erstelle Mapping zu bekanntem Pr√§dikat
            self._create_adaptive_mapping(predicate)
    
    def _add_fact_to_db(self, fact: str, source: str, confidence: float):
        """F√ºgt Fact zur Datenbank hinzu"""
        try:
            response = requests.post(
                f"{BACKEND_URL}/api/facts",
                json={
                    'statement': fact,
                    'source': source,
                    'confidence': confidence
                },
                headers={'Content-Type': 'application/json'},
                timeout=10
            )
            
            if response.ok and response.json().get('success'):
                self.stats['facts_accepted'] += 1
                print(f"      üíæ Added: {fact[:50]}...")
                return True
                
        except:
            pass
        return False
    
    def _find_better_mapping(self, bad_predicate: str, test_results: List[Tuple[str, float]]):
        """
        Phase 5: ADAPT
        Findet bessere Mappings f√ºr schlechte Pr√§dikate
        """
        print(f"    üîÑ Finding better mapping for {bad_predicate}...")
        
        # Teste alternative Pr√§dikate
        alternatives = list(self.known_good_predicates.keys())
        best_mapping = None
        best_score = 0
        
        for alt_predicate in alternatives:
            # Teste einen Beispiel-Fact mit alternativem Pr√§dikat
            if test_results:
                original_fact = test_results[0][0]
                # Ersetze Pr√§dikat
                if '(' in original_fact:
                    args = original_fact[original_fact.index('('):]
                    alt_fact = alt_predicate + args
                    
                    alt_confidence = self.test_fact_confidence(alt_fact)
                    
                    if alt_confidence > best_score:
                        best_score = alt_confidence
                        best_mapping = alt_predicate
        
        if best_mapping and best_score > 0.5:
            self.learned_mappings[bad_predicate] = best_mapping
            print(f"      ‚úÖ Learned: {bad_predicate} ‚Üí {best_mapping} ({best_score:.1%})")
            self.stats['confidence_improvements'] += 1
    
    def _create_adaptive_mapping(self, unknown_predicate: str):
        """Erstellt adaptives Mapping f√ºr unbekanntes Pr√§dikat"""
        # Analysiere Pr√§dikat-Name f√ºr Hinweise
        if 'Has' in unknown_predicate or 'Property' in unknown_predicate:
            self.learned_mappings[unknown_predicate] = 'HasProperty'
        elif 'Is' in unknown_predicate or 'Type' in unknown_predicate:
            self.learned_mappings[unknown_predicate] = 'IsA'
        elif 'Cause' in unknown_predicate or 'Lead' in unknown_predicate:
            self.learned_mappings[unknown_predicate] = 'Causes'
        elif 'Part' in unknown_predicate or 'Contains' in unknown_predicate:
            self.learned_mappings[unknown_predicate] = 'HasPart'
        else:
            # Default fallback
            self.learned_mappings[unknown_predicate] = 'HasProperty'
        
        print(f"      üìù Created mapping: {unknown_predicate} ‚Üí {self.learned_mappings[unknown_predicate]}")
    
    def run_exploration_cycle(self, max_predicates: int = 5):
        """
        Phase 6: EVOLVE
        F√ºhrt einen kompletten Explorations-Zyklus durch
        """
        print(f"\n{'='*60}")
        print("üöÄ STARTING AUTONOMOUS EXPLORATION CYCLE")
        print(f"{'='*60}")
        
        # 1. Discover
        new_predicates = self.discover_new_predicates()
        
        if not new_predicates:
            print("\n‚ö†Ô∏è No new predicates to explore")
            return
        
        # 2. Select predicates to explore
        predicates_to_explore = list(new_predicates)[:max_predicates]
        
        print(f"\nüìä Exploring {len(predicates_to_explore)} predicates...")
        
        for i, predicate in enumerate(predicates_to_explore, 1):
            print(f"\n[{i}/{len(predicates_to_explore)}] Exploring: {predicate}")
            print("-"*40)
            
            # 2. Explore with LLM
            suggested_facts = self.explore_predicate_with_llm(predicate)
            
            if not suggested_facts:
                continue
            
            # 3. Test each fact
            test_results = []
            for fact in suggested_facts[:3]:  # Test max 3 facts per predicate
                confidence = self.test_fact_confidence(fact)
                test_results.append((fact, confidence))
                print(f"    Test: {fact[:50]}... ‚Üí {confidence:.1%}")
            
            # 4. Learn from results
            self.learn_from_exploration(predicate, test_results)
            
            # Small delay
            time.sleep(0.5)
        
        # Save exploration history
        self._save_exploration_log()
        
        # Print summary
        self._print_summary()
    
    def _save_exploration_log(self):
        """Speichert Explorations-Historie"""
        log_entry = {
            'timestamp': datetime.now().isoformat(),
            'predicates_discovered': self.stats['predicates_discovered'],
            'facts_generated': self.stats['facts_generated'],
            'facts_accepted': self.stats['facts_accepted'],
            'learned_mappings': self.learned_mappings,
            'predicate_scores': dict(self.predicate_scores),
            'known_good_predicates': self.known_good_predicates
        }
        
        try:
            # Load existing log
            try:
                with open(EXPLORATION_LOG, 'r') as f:
                    log = json.load(f)
            except:
                log = []
            
            # Append new entry
            log.append(log_entry)
            
            # Save updated log
            with open(EXPLORATION_LOG, 'w') as f:
                json.dump(log, f, indent=2)
                
            print(f"\nüíæ Exploration log saved to {EXPLORATION_LOG}")
            
        except Exception as e:
            print(f"\n‚ö†Ô∏è Could not save log: {e}")
    
    def _print_summary(self):
        """Druckt Zusammenfassung"""
        print(f"\n{'='*60}")
        print("üìä EXPLORATION SUMMARY")
        print(f"{'='*60}")
        
        print(f"\nüîç Discovered: {self.stats['predicates_discovered']} new predicates")
        print(f"üìù Generated: {self.stats['facts_generated']} exploratory facts")
        print(f"‚úÖ Accepted: {self.stats['facts_accepted']} facts into KB")
        print(f"üìà Improvements: {self.stats['confidence_improvements']} confidence boosts")
        
        if self.learned_mappings:
            print(f"\nüß† LEARNED MAPPINGS:")
            for bad, good in self.learned_mappings.items():
                print(f"  {bad} ‚Üí {good}")
        
        if self.known_good_predicates:
            print(f"\n‚ú® GOOD PREDICATES (>70% confidence):")
            for pred, score in sorted(self.known_good_predicates.items(), 
                                     key=lambda x: x[1], reverse=True)[:5]:
                print(f"  {pred}: {score:.1%}")
        
        print(f"\n{'='*60}")
    
    def run_continuous_learning(self, cycles: int = 3, delay_minutes: int = 5):
        """
        Kontinuierliches Lernen √ºber mehrere Zyklen
        """
        print(f"\nüîÑ STARTING CONTINUOUS LEARNING ({cycles} cycles)")
        print(f"   Delay between cycles: {delay_minutes} minutes")
        print("="*60)
        
        for cycle in range(1, cycles + 1):
            print(f"\n\n{'='*60}")
            print(f"üîÑ CYCLE {cycle}/{cycles}")
            print(f"{'='*60}")
            
            # Run exploration
            self.run_exploration_cycle()
            
            # Evolve: Das System wird mit jedem Zyklus schlauer
            print(f"\nüí≠ System has learned {len(self.learned_mappings)} mappings")
            print(f"   Known good predicates: {len(self.known_good_predicates)}")
            
            if cycle < cycles:
                print(f"\n‚è±Ô∏è Waiting {delay_minutes} minutes before next cycle...")
                time.sleep(delay_minutes * 60)
        
        print(f"\n\n{'='*60}")
        print("‚úÖ CONTINUOUS LEARNING COMPLETE")
        print(f"{'='*60}")

def main():
    """Main execution"""
    print("\nü§ñ HAK-GAL AUTONOMOUS PREDICATE EXPLORER")
    print("="*60)
    print("This system autonomously:")
    print("1. Discovers new predicates")
    print("2. Explores them with LLM")
    print("3. Tests HRM confidence")
    print("4. Learns successful patterns")
    print("5. Adapts and evolves")
    print("="*60)
    
    explorer = AutonomousPredicateExplorer()
    
    # Menu
    print("\nüéØ Choose exploration mode:")
    print("1. Single exploration cycle (quick)")
    print("2. Continuous learning (3 cycles)")
    print("3. 24/7 autonomous mode (runs forever)")
    
    choice = input("\nEnter choice (1-3): ")
    
    if choice == '1':
        explorer.run_exploration_cycle(max_predicates=5)
        
    elif choice == '2':
        cycles = int(input("Number of cycles (default 3): ") or "3")
        delay = int(input("Minutes between cycles (default 5): ") or "5")
        explorer.run_continuous_learning(cycles=cycles, delay_minutes=delay)
        
    elif choice == '3':
        print("\nüîÑ AUTONOMOUS MODE - Press Ctrl+C to stop")
        try:
            while True:
                explorer.run_exploration_cycle(max_predicates=10)
                print("\n‚è±Ô∏è Waiting 10 minutes before next exploration...")
                time.sleep(600)  # 10 minutes
        except KeyboardInterrupt:
            print("\n‚èπÔ∏è Autonomous exploration stopped")
    
    print("\n‚úÖ Exploration complete!")
    print(f"   Check {EXPLORATION_LOG} for detailed history")

if __name__ == "__main__":
    main()
