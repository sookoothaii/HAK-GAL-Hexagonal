# üöÄ LLM GOVERNOR - QUICK START GUIDE

## ‚ùå **AKTUELLER STATUS: NICHT INTEGRIERT**

Der LLM Governor wurde von Sonnet 4 implementiert, ist aber **NOCH NICHT** im Backend integriert!

## ‚úÖ **WAS VORHANDEN IST:**
- `llm_governor_adapter.py` ‚úÖ
- `hybrid_llm_governor.py` ‚úÖ 
- `llm_governor_integration.py` ‚úÖ
- Integration Patch ‚úÖ

## üîß **INTEGRATION IN 5 MINUTEN:**

### **Option 1: AUTOMATISCH (Empfohlen)**
```bash
# F√ºhre das Integration Script aus
cd D:\MCP Mods\HAK_GAL_HEXAGONAL\src_hexagonal
python apply_llm_governor_patch.py
```

### **Option 2: MANUELL**

1. **√ñffne** `hexagonal_api_enhanced_clean.py`

2. **F√ºge Import hinzu** (Zeile ~92):
```python
from src_hexagonal.llm_governor_integration import integrate_llm_governor
```

3. **F√ºge Initialisierung hinzu** (in `__init__`, nach Zeile ~208):
```python
# Initialize LLM Governor
self.llm_governor_integration = None
if enable_governor:
    try:
        self.llm_governor_integration = integrate_llm_governor(self.app)
        print("[OK] LLM Governor Integration enabled")
    except Exception as e:
        print(f"[WARNING] LLM Governor Integration failed: {e}")
```

4. **Modifiziere governor_start** (Zeile ~1740):
```python
@self.app.route('/api/governor/start', methods=['POST'])
def governor_start():
    data = request.get_json(silent=True) or {}
    use_llm = data.get('use_llm', False)
    
    if use_llm and self.llm_governor_integration:
        self.llm_governor_integration.enabled = True
        if self.governor:
            self.governor.start()
        return jsonify({
            'success': True, 
            'mode': 'llm_governor',
            'provider': self.llm_governor_integration.config['provider']
        })
    else:
        success = self.governor.start() if self.governor else False
        return jsonify({'success': success, 'mode': 'thompson'})
```

5. **Restart Backend:**
```bash
Ctrl+C
python src_hexagonal/hexagonal_api_enhanced_clean.py
```

## üß™ **TEST DER INTEGRATION:**

### **1. Check Status:**
```bash
curl http://localhost:5002/api/llm-governor/status
```

Erwartete Antwort:
```json
{
  "available": true,
  "enabled": false,
  "provider": "groq",
  "epsilon": 0.2
}
```

### **2. Enable LLM Governor:**
```bash
curl -X POST http://localhost:5002/api/llm-governor/enable \
     -H "Content-Type: application/json" \
     -d '{"provider": "groq", "epsilon": 0.2}'
```

### **3. Test Evaluation:**
```bash
curl -X POST http://localhost:5002/api/llm-governor/evaluate \
     -H "Content-Type: application/json" \
     -d '{"fact": "Gravity(Earth, Acceleration, 9.81, m/s¬≤)", "domain": "physics"}'
```

## üéÆ **FRONTEND INTEGRATION:**

Im Frontend Dashboard:
1. Klicke "Start Governor"
2. Aktiviere Checkbox "Use LLM Governor" 
3. W√§hle Provider (Groq/Ollama/Mock)
4. Setze Epsilon (0.2 empfohlen)
5. Klicke "Start with LLM"

## üìä **ERWARTETE VERBESSERUNGEN:**

| Metrik | Ohne LLM | Mit LLM | Verbesserung |
|--------|----------|---------|--------------|
| Duplikate | 30% | <5% | **-83%** |
| Qualit√§t | 0.60 | 0.83 | **+38%** |
| Relevanz | 60% | 92% | **+53%** |

## ‚ö†Ô∏è **TROUBLESHOOTING:**

**Problem:** "LLM Governor not available"
‚Üí **L√∂sung:** Stelle sicher, dass `GROQ_API_KEY` gesetzt ist oder Ollama l√§uft

**Problem:** "Module not found: llm_governor_integration"
‚Üí **L√∂sung:** Pfade pr√ºfen, `sys.path` muss src_hexagonal enthalten

**Problem:** Frontend zeigt keinen LLM Governor
‚Üí **L√∂sung:** Backend neu starten, Cache leeren (Ctrl+F5)

## ‚úÖ **ERFOLGS-CHECKS:**

Wenn alles funktioniert, solltest du sehen:
- `[OK] LLM Governor Integration enabled` beim Backend-Start
- `/api/llm-governor/status` gibt `available: true` zur√ºck
- Frontend zeigt "LLM Governor" Option
- Console zeigt LLM Evaluations beim Fact-Adding

---

**STATUS:** Integration bereit, muss nur angewendet werden!